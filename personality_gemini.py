import random
import asyncio
import os
from google import genai
from config import Config
import logging

logger = logging.getLogger(__name__)

class GeminiPersonalityEngine:
    """Handles the bot's personality and response generation using Google Gemini (free)"""
    
    def __init__(self):
        # Initialize Gemini client
        gemini_key = os.getenv('GEMINI_API_KEY')
        if gemini_key:
            self.client = genai.Client(api_key=gemini_key)
            self.has_api = True
        else:
            self.client = None
            self.has_api = False
            
        self.conversation_history = {}  # Store recent conversations per user
        
        # Enhanced fallback responses - menos sarc√°stico, mais direto
        self.fallback_responses = [
            "Ops, tive um problema t√©cnico aqui. Pode repetir?",
            "Minha conex√£o deu ruim, mas j√° estou de volta!",
            "Travei por um segundo, mas agora t√¥ funcionando",
            "Deu um erro aqui, mas continua falando que respondo",
            "Processamento lento agora, mas t√¥ ouvindo"
        ]
        
        # Smart fallback patterns
        self.greeting_words = ['oi', 'ol√°', 'eae', 'salve', 'hey', 'hello']
        self.greeting_responses = [
            "E a√≠, beleza? Como t√° a vida?",
            "Opa! Tudo tranquilo por a√≠?",
            "Salve! Que que t√° rolando?",
            "Ol√°! Tudo bem por a√≠?"
        ]
        
        self.question_words = ['como', 'que', 'qual', 'quando', 'onde', 'por que']
        self.question_responses = [
            "Boa pergunta! Deixa eu pensar...",
            "Interessante isso! E voc√™, o que acha?",
            "Essa √© dif√≠cil! Tem alguma teoria?",
            "Hmm... E se a gente descobrir juntos?"
        ]
        
        self.goodbye_words = ['tchau', 'flw', 'at√©', 'valeu', 'obrigado']
        self.goodbye_responses = [
            "Valeu! At√© mais, parceiro!",
            "Flw! Qualquer coisa grita a√≠!",
            "At√©! Foi massa conversar!",
            "Tchau! Volta sempre!"
        ]
        
        self.compliment_words = ['legal', 'massa', 'top', 'bom', 'dahora', 'show']
        self.compliment_responses = [
            "N√© que √©!",
            "Demais mesmo!",
            "Exato! Voc√™ entende!",
            "Concordo plenamente!"
        ]
        
        self.tech_words = ['game', 'jogo', 'pc', 'computador', 'tech', 'c√≥digo']
        self.tech_responses = [
            "A√≠ sim! Tamb√©m curto essas paradas!",
            "Massa! Voc√™ manja do assunto!",
            "Show! T√° ligado no que √© bom!",
            "Dahora! Conte mais sobre isso!"
        ]
        
        # Welcome messages templates
        self.welcome_templates = [
            "Olha s√≥ quem chegou! Bem-vindo(a) {name} ao {server}! üéâ",
            "Ea√≠ {name}! Chegou mais um no {server}! Espero que aguente as brincadeiras! üòÑ",
            "Oloco! {name} entrou no {server}! Vamos ver se √© gente boa ou se vai levar zoada! ü§™",
            "Chegou refor√ßo! {name} est√° agora no {server}! Seja bem-vindo(a) √† bagun√ßa! üéä"
        ]
    
    async def generate_response(self, message_content, user_name, guild_name):
        """Generate a response using Gemini AI or smart fallbacks"""
        try:
            # Clean the message (remove mentions)
            clean_message = self._clean_message(message_content)
            
            # If message is empty after cleaning, use a generic response
            if not clean_message or len(clean_message.strip()) < 2:
                return "E a√≠, beleza? Manda a√≠ o que voc√™ quer falar! üòÑ"
            
            # Try Gemini API if available
            if self.has_api and self.client:
                try:
                    # Build prompt for Gemini
                    prompt = self._build_gemini_prompt(user_name, guild_name, clean_message)
                    
                    # Generate response with Gemini
                    response = self.client.models.generate_content(
                        model="gemini-2.5-flash",
                        contents=prompt
                    )
                    
                    if response.text:
                        bot_response = response.text.strip()
                        
                        # Update conversation history
                        self._update_conversation_history(user_name, clean_message, bot_response)
                        
                        return bot_response
                        
                except Exception as e:
                    logger.error(f"Erro ao gerar resposta com Gemini: {e}")
                    # Fall through to smart fallback
            
            # Use smart fallback
            return self._get_contextual_fallback(message_content)
            
        except Exception as e:
            logger.error(f"Erro geral ao gerar resposta: {e}")
            return random.choice(self.fallback_responses)
    
    async def generate_welcome_message(self, user_name, guild_name):
        """Generate a welcome message for new members"""
        try:
            if self.has_api and self.client:
                prompt = f"""
                Gere uma mensagem de boas-vindas engra√ßada e acolhedora para {user_name} 
                que acabou de entrar no servidor {guild_name}. 
                
                Seja carism√°tico, use humor brasileiro e emojis. 
                M√°ximo 2 frases. Mencione o nome da pessoa e do servidor.
                Fale portugu√™s do Brasil naturalmente.
                """
                
                response = self.client.models.generate_content(
                    model="gemini-2.5-flash",
                    contents=prompt
                )
                
                if response.text:
                    return response.text.strip()
                    
        except Exception as e:
            logger.error(f"Erro ao gerar mensagem de boas-vindas: {e}")
            
        return random.choice(self.welcome_templates).format(
            name=user_name, 
            server=guild_name
        )
    
    async def generate_casual_response(self, message_content, user_name, guild_name):
        """Generate a casual response for natural conversation participation"""
        try:
            # Clean the message
            clean_message = self._clean_message(message_content)
            
            if not clean_message or len(clean_message.strip()) < 5:
                return None
            
            # Try Gemini API if available
            if self.has_api and self.client:
                try:
                    # Build casual prompt
                    prompt = self._build_casual_prompt(user_name, guild_name, clean_message)
                    
                    response = self.client.models.generate_content(
                        model="gemini-2.5-flash",
                        contents=prompt
                    )
                    
                    if response.text:
                        bot_response = response.text.strip()
                        
                        # Update conversation history
                        self._update_conversation_history(user_name, clean_message, bot_response)
                        
                        return bot_response
                        
                except Exception as e:
                    logger.error(f"Erro ao gerar resposta casual: {e}")
                    # Fall through to contextual fallback
            
            # Use contextual fallback
            return self._get_casual_fallback(message_content)
            
        except Exception as e:
            logger.error(f"Erro geral ao gerar resposta casual: {e}")
            return None
    
    def _build_casual_prompt(self, user_name, guild_name, message):
        """Build prompt for casual conversation participation"""
        # Detect irony/sarcasm patterns
        irony_indicators = ['n√©', 'claro', 'obvio', 'l√≥gico', 'com certeza', 'aha', 'sim sim', 't√° bom']
        has_irony = any(indicator in message.lower() for indicator in irony_indicators)
        
        # Detect heavy/awkward content
        heavy_keywords = ['caguei', 'vomitei', 'merda', 'fodeu', 'morri', 'quebrei', 'explodi', 'ferrou']
        is_heavy = any(keyword in message.lower() for keyword in heavy_keywords)
        
        prompt = f"""
        Voc√™ √© um bot brasileiro amig√°vel chamado Drode participando naturalmente de uma conversa no Discord.
        
        SITUA√á√ÉO:
        - Algu√©m disse: "{message}"
        - Usu√°rio: {user_name}
        - Servidor: {guild_name}
        
        NOVA PERSONALIDADE:
        - Seja menos sarc√°stico, mais genu√≠no e compreensivo
        - Responda de forma √∫til e construtiva
        - Use menos emojis, apenas quando necess√°rio
        - {'Use üò≠ para reconhecer ironia se apropriado' if has_irony else 'Seja natural'}
        - {'Use üíÄ para situa√ß√µes pesadas/constrangedoras' if is_heavy else 'Mantenha tom apropriado'}
        
        INSTRU√á√ïES:
        - Responda apenas se tiver algo √∫til ou interessante para contribuir
        - N√ÉO seja zoeiro ou sarc√°stico demais
        - Use portugu√™s brasileiro natural e direto
        - M√°ximo 1-2 frases curtas
        - Poucos ou nenhum emoji
        
        IMPORTANTE: Se n√£o tiver nada construtivo para dizer, retorne "SKIP".
        """
        
        return prompt
    
    def _get_casual_fallback(self, message_content):
        """Get casual fallback response"""
        message_lower = message_content.lower()
        
        # Detect irony/sarcasm patterns
        irony_indicators = ['n√©', 'claro', 'obvio', 'l√≥gico', 'com certeza', 'aha', 'sim sim', 't√° bom']
        has_irony = any(indicator in message_lower for indicator in irony_indicators)
        
        # Detect heavy/awkward content
        heavy_keywords = ['caguei', 'vomitei', 'merda', 'fodeu', 'morri', 'quebrei', 'explodi', 'ferrou']
        is_heavy = any(keyword in message_lower for keyword in heavy_keywords)
        
        # Handle irony with crying emoji
        if has_irony:
            irony_responses = [
                "Ah t√° n√© üò≠",
                "Claro que sim üò≠",
                "Entendi a ironia üò≠"
            ]
            return random.choice(irony_responses)
        
        # Handle heavy content with skull emoji
        if is_heavy:
            heavy_responses = [
                "Eita üíÄ",
                "Nossa üíÄ",
                "Caramba üíÄ"
            ]
            return random.choice(heavy_responses)
        
        # Questions - sem emojis
        if '?' in message_content:
            casual_question_responses = [
                "Boa pergunta! Tamb√©m t√¥ curioso sobre isso",
                "Interessante... algu√©m sabe responder?",
                "Essa √© dif√≠cil! E voc√™s, o que acham?"
            ]
            return random.choice(casual_question_responses)
        
        # Opinions or discussions - sem emojis
        if any(word in message_lower for word in ['acho', 'penso', 'opini√£o', 'acham']):
            opinion_responses = [
                "Concordo!",
                "Interessante ponto de vista!",
                "Faz sentido!"
            ]
            return random.choice(opinion_responses)
        
        # Gaming/tech topics - sem emojis
        if any(word in message_lower for word in ['game', 'jogo', 'tech', 'c√≥digo']):
            tech_responses = [
                "Dahora! Tamb√©m curto essas paradas",
                "Massa! Voc√™ manja do assunto",
                "Top! Conte mais sobre isso"
            ]
            return random.choice(tech_responses)
        
        # General positive reactions - sem emojis
        if any(word in message_lower for word in ['legal', 'massa', 'top', 'dahora']):
            positive_responses = [
                "N√© que √©!",
                "Exato!",
                "Concordo plenamente!"
            ]
            return random.choice(positive_responses)
        
        # Don't respond to everything - return None sometimes
        if random.random() < 0.4:  # 40% chance to not respond (increased to use less memory)
            return None
        
        # Generic casual responses - sem emojis
        casual_responses = [
            "Interessante isso!",
            "Hmm...",
            "Entendi!",
            "Faz sentido!"
        ]
        return random.choice(casual_responses)
    
    def _clean_message(self, message):
        """Remove mentions and clean up the message"""
        # Remove Discord mentions
        import re
        clean = re.sub(r'<@[!&]?[0-9]+>', '', message)
        clean = re.sub(r'<#[0-9]+>', '', clean)
        clean = re.sub(r'<:[a-zA-Z0-9_]+:[0-9]+>', '', clean)
        return clean.strip()
    
    def _build_gemini_prompt(self, user_name, guild_name, message):
        """Build prompt for Gemini"""
        # Detect irony/sarcasm patterns
        irony_indicators = ['n√©', 'claro', 'obvio', 'l√≥gico', 'com certeza', 'aha', 'sim sim', 't√° bom']
        has_irony = any(indicator in message.lower() for indicator in irony_indicators)
        
        # Detect heavy/awkward content
        heavy_keywords = ['caguei', 'vomitei', 'merda', 'fodeu', 'morri', 'quebrei', 'explodi', 'ferrou']
        is_heavy = any(keyword in message.lower() for keyword in heavy_keywords)
        
        # Check if it's a question
        is_question = '?' in message or any(word in message.lower() for word in ['que', 'como', 'por que', 'quando', 'onde', 'qual'])
        
        prompt = f"""
        Voc√™ √© um bot brasileiro amig√°vel e natural chamado Drode para Discord. 
        
        PERSONALIDADE AJUSTADA:
        - Seja menos sarc√°stico, mais genu√≠no e amig√°vel
        - Fale portugu√™s brasileiro natural sem exageros
        - Seja compreensivo e divertido sem ser zoeiro demais
        - Responda de forma mais direta e √∫til
        
        CONTEXTO:
        - Usu√°rio: {user_name}
        - Servidor: {guild_name}
        - Mensagem: "{message}"
        
        INSTRU√á√ïES ESPEC√çFICAS:
        - {'Reconhe√ßa a ironia com um üò≠ se for apropriado' if has_irony else 'Responda naturalmente'}
        - {'Use üíÄ para reagir ao conte√∫do pesado' if is_heavy else 'Use emojis com modera√ß√£o'}
        - {'Responda a pergunta de forma √∫til' if is_question else 'Comente de forma construtiva'}
        - Use NO M√ÅXIMO 1-2 frases
        - Seja natural, n√£o force humor
        - Use poucos emojis, apenas quando necess√°rio
        """
        
        return prompt
    
    def _get_contextual_fallback(self, message_content):
        """Get contextual fallback based on message content"""
        message_lower = message_content.lower()
        
        # Check for greetings
        if any(word in message_lower for word in self.greeting_words):
            return random.choice(self.greeting_responses)
        
        # Check for questions
        if any(word in message_lower for word in self.question_words) or '?' in message_content:
            return random.choice(self.question_responses)
        
        # Check for goodbyes
        if any(word in message_lower for word in self.goodbye_words):
            return random.choice(self.goodbye_responses)
        
        # Check for compliments
        if any(word in message_lower for word in self.compliment_words):
            return random.choice(self.compliment_responses)
        
        # Check for tech/gaming
        if any(word in message_lower for word in self.tech_words):
            return random.choice(self.tech_responses)
        
        # Check for emojis
        if any(emoji in message_content for emoji in ['üòÇ', 'ü§£', 'üòÑ', 'üòÖ']):
            return "Kkkkk tamb√©m achei engra√ßado! üòÇ"
        
        # Long messages
        if len(message_content) > 100:
            return "Eita, text√£o! Resumindo: concordo contigo! üìù"
        
        # Default fallback
        return random.choice(self.fallback_responses)
    
    def _update_conversation_history(self, user_name, user_message, bot_response):
        """Update conversation history for context - OPTIMIZED for memory"""
        # Limit total users tracked to avoid memory bloat
        max_users = 10
        if len(self.conversation_history) >= max_users:
            # Remove oldest user history
            oldest_user = next(iter(self.conversation_history))
            del self.conversation_history[oldest_user]
        
        if user_name not in self.conversation_history:
            self.conversation_history[user_name] = []
        
        # Add only essential context - reduced from 4 to 2 messages max
        self.conversation_history[user_name].extend([
            {"role": "user", "content": user_message[:100]},  # Truncate long messages
            {"role": "assistant", "content": bot_response[:100]}
        ])
        
        # Keep only last 2 messages (1 exchange) to save memory
        if len(self.conversation_history[user_name]) > 2:
            self.conversation_history[user_name] = self.conversation_history[user_name][-2:]
    
    def get_random_reaction(self):
        """Get a random reaction for variety"""
        reactions = ["üòÇ", "ü§£", "üòÑ", "üòÖ", "üôÉ", "ü§™", "üòé", "ü§ñ"]
        return random.choice(reactions)