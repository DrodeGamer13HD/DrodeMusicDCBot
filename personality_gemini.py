import random
import asyncio
import os
from google import genai
from config import Config
import logging

logger = logging.getLogger(__name__)

class GeminiPersonalityEngine:
    """Handles the bot's personality and response generation using Google Gemini (free)"""
    
    def __init__(self):
        # Initialize Gemini client
        gemini_key = os.getenv('GEMINI_API_KEY')
        if gemini_key:
            self.client = genai.Client(api_key=gemini_key)
            self.has_api = True
        else:
            self.client = None
            self.has_api = False
            
        self.conversation_history = {}  # Store recent conversations per user
        
        # Enhanced fallback responses - menos sarcÃ¡stico, mais direto
        self.fallback_responses = [
            "Ops, tive um problema tÃ©cnico aqui. Pode repetir?",
            "Minha conexÃ£o deu ruim, mas jÃ¡ estou de volta!",
            "Travei por um segundo, mas agora tÃ´ funcionando",
            "Deu um erro aqui, mas continua falando que respondo",
            "Processamento lento agora, mas tÃ´ ouvindo"
        ]
        
        # Smart fallback patterns
        self.greeting_words = ['oi', 'olÃ¡', 'eae', 'salve', 'hey', 'hello']
        self.greeting_responses = [
            "E aÃ­, beleza? Como tÃ¡ a vida?",
            "Opa! Tudo tranquilo por aÃ­?",
            "Salve! Que que tÃ¡ rolando?",
            "OlÃ¡! Tudo bem por aÃ­?"
        ]
        
        self.question_words = ['como', 'que', 'qual', 'quando', 'onde', 'por que']
        self.question_responses = [
            "Boa pergunta! Deixa eu pensar...",
            "Interessante isso! E vocÃª, o que acha?",
            "Essa Ã© difÃ­cil! Tem alguma teoria?",
            "Hmm... E se a gente descobrir juntos?"
        ]
        
        self.goodbye_words = ['tchau', 'flw', 'atÃ©', 'valeu', 'obrigado']
        self.goodbye_responses = [
            "Valeu! AtÃ© mais, parceiro!",
            "Flw! Qualquer coisa grita aÃ­!",
            "AtÃ©! Foi massa conversar!",
            "Tchau! Volta sempre!"
        ]
        
        self.compliment_words = ['legal', 'massa', 'top', 'bom', 'dahora', 'show']
        self.compliment_responses = [
            "NÃ© que Ã©!",
            "Demais mesmo!",
            "Exato! VocÃª entende!",
            "Concordo plenamente!"
        ]
        
        self.tech_words = ['game', 'jogo', 'pc', 'computador', 'tech', 'cÃ³digo']
        self.tech_responses = [
            "AÃ­ sim! TambÃ©m curto essas paradas!",
            "Massa! VocÃª manja do assunto!",
            "Show! TÃ¡ ligado no que Ã© bom!",
            "Dahora! Conte mais sobre isso!"
        ]
        
        # Welcome messages templates
        self.welcome_templates = [
            "Olha sÃ³ quem chegou! Bem-vindo(a) {name} ao {server}! ğŸ‰",
            "EaÃ­ {name}! Chegou mais um no {server}! Espero que aguente as brincadeiras! ğŸ˜„",
            "Oloco! {name} entrou no {server}! Vamos ver se Ã© gente boa ou se vai levar zoada! ğŸ¤ª",
            "Chegou reforÃ§o! {name} estÃ¡ agora no {server}! Seja bem-vindo(a) Ã  bagunÃ§a! ğŸŠ"
        ]
    
    async def generate_response(self, message_content, user_name, guild_name):
        """Generate a response using Gemini AI or smart fallbacks"""
        try:
            # Clean the message (remove mentions)
            clean_message = self._clean_message(message_content)
            
            # If message is empty after cleaning, use a generic response
            if not clean_message or len(clean_message.strip()) < 2:
                return "E aÃ­, beleza? Manda aÃ­ o que vocÃª quer falar! ğŸ˜„"
            
            # Try Gemini API if available
            if self.has_api and self.client:
                try:
                    # Build prompt for Gemini
                    prompt = self._build_gemini_prompt(user_name, guild_name, clean_message)
                    
                    # Generate response with Gemini
                    response = self.client.models.generate_content(
                        model="gemini-2.5-flash",
                        contents=prompt
                    )
                    
                    if response.text:
                        bot_response = response.text.strip()
                        
                        # Update conversation history
                        self._update_conversation_history(user_name, clean_message, bot_response)
                        
                        return bot_response
                        
                except Exception as e:
                    logger.error(f"Erro ao gerar resposta com Gemini: {e}")
                    # Fall through to smart fallback
            
            # Use smart fallback
            return self._get_contextual_fallback(message_content)
            
        except Exception as e:
            logger.error(f"Erro geral ao gerar resposta: {e}")
            return random.choice(self.fallback_responses)
    
    async def generate_welcome_message(self, user_name, guild_name):
        """Generate a welcome message for new members"""
        try:
            if self.has_api and self.client:
                prompt = f"""
                Gere uma mensagem de boas-vindas engraÃ§ada e acolhedora para {user_name} 
                que acabou de entrar no servidor {guild_name}. 
                
                Seja carismÃ¡tico, use humor brasileiro e emojis. 
                MÃ¡ximo 2 frases. Mencione o nome da pessoa e do servidor.
                Fale portuguÃªs do Brasil naturalmente.
                """
                
                response = self.client.models.generate_content(
                    model="gemini-2.5-flash",
                    contents=prompt
                )
                
                if response.text:
                    return response.text.strip()
                    
        except Exception as e:
            logger.error(f"Erro ao gerar mensagem de boas-vindas: {e}")
            
        return random.choice(self.welcome_templates).format(
            name=user_name, 
            server=guild_name
        )
    
    async def generate_casual_response(self, message_content, user_name, guild_name):
        """Generate a casual response for natural conversation participation"""
        try:
            # Clean the message
            clean_message = self._clean_message(message_content)
            
            if not clean_message or len(clean_message.strip()) < 5:
                return None
            
            # Try Gemini API if available
            if self.has_api and self.client:
                try:
                    # Build casual prompt
                    prompt = self._build_casual_prompt(user_name, guild_name, clean_message)
                    
                    response = self.client.models.generate_content(
                        model="gemini-2.5-flash",
                        contents=prompt
                    )
                    
                    if response.text:
                        bot_response = response.text.strip()
                        
                        # Update conversation history
                        self._update_conversation_history(user_name, clean_message, bot_response)
                        
                        return bot_response
                        
                except Exception as e:
                    logger.error(f"Erro ao gerar resposta casual: {e}")
                    # Fall through to contextual fallback
            
            # Use contextual fallback
            return self._get_casual_fallback(message_content)
            
        except Exception as e:
            logger.error(f"Erro geral ao gerar resposta casual: {e}")
            return None
    
    def _build_casual_prompt(self, user_name, guild_name, message):
        """Build prompt for casual conversation participation"""
        # Detect irony/sarcasm patterns
        irony_indicators = ['nÃ©', 'claro', 'obvio', 'lÃ³gico', 'com certeza', 'aha', 'sim sim', 'tÃ¡ bom']
        has_irony = any(indicator in message.lower() for indicator in irony_indicators)
        
        # Detect heavy/awkward content
        heavy_keywords = ['caguei', 'vomitei', 'merda', 'fodeu', 'morri', 'quebrei', 'explodi', 'ferrou']
        is_heavy = any(keyword in message.lower() for keyword in heavy_keywords)
        
        prompt = f"""
        VocÃª Ã© um bot brasileiro amigÃ¡vel chamado Drode participando naturalmente de uma conversa no Discord.
        
        SITUAÃ‡ÃƒO:
        - AlguÃ©m disse: "{message}"
        - UsuÃ¡rio: {user_name}
        - Servidor: {guild_name}
        
        NOVA PERSONALIDADE:
        - Seja menos sarcÃ¡stico, mais genuÃ­no e compreensivo
        - Responda de forma Ãºtil e construtiva
        - Use menos emojis, apenas quando necessÃ¡rio
        - {'Use ğŸ˜­ para reconhecer ironia se apropriado' if has_irony else 'Seja natural'}
        - {'Use ğŸ’€ para situaÃ§Ãµes pesadas/constrangedoras' if is_heavy else 'Mantenha tom apropriado'}
        
        INSTRUÃ‡Ã•ES:
        - Responda apenas se tiver algo Ãºtil ou interessante para contribuir
        - NÃƒO seja zoeiro ou sarcÃ¡stico demais
        - Use portuguÃªs brasileiro natural e direto
        - MÃ¡ximo 1-2 frases curtas
        - Poucos ou nenhum emoji
        
        IMPORTANTE: Se nÃ£o tiver nada construtivo para dizer, retorne "SKIP".
        """
        
        return prompt
    
    def _get_casual_fallback(self, message_content):
        """Get casual fallback response"""
        message_lower = message_content.lower()
        
        # Detect irony/sarcasm patterns
        irony_indicators = ['nÃ©', 'claro', 'obvio', 'lÃ³gico', 'com certeza', 'aha', 'sim sim', 'tÃ¡ bom']
        has_irony = any(indicator in message_lower for indicator in irony_indicators)
        
        # Detect heavy/awkward content
        heavy_keywords = ['caguei', 'vomitei', 'merda', 'fodeu', 'morri', 'quebrei', 'explodi', 'ferrou']
        is_heavy = any(keyword in message_lower for keyword in heavy_keywords)
        
        # Handle irony with crying emoji
        if has_irony:
            irony_responses = [
                "Ah tÃ¡ nÃ© ğŸ˜­",
                "Claro que sim ğŸ˜­",
                "Entendi a ironia ğŸ˜­"
            ]
            return random.choice(irony_responses)
        
        # Handle heavy content with skull emoji
        if is_heavy:
            heavy_responses = [
                "Eita ğŸ’€",
                "Nossa ğŸ’€",
                "Caramba ğŸ’€"
            ]
            return random.choice(heavy_responses)
        
        # Questions - sem emojis
        if '?' in message_content:
            casual_question_responses = [
                "Boa pergunta! TambÃ©m tÃ´ curioso sobre isso",
                "Interessante... alguÃ©m sabe responder?",
                "Essa Ã© difÃ­cil! E vocÃªs, o que acham?"
            ]
            return random.choice(casual_question_responses)
        
        # Opinions or discussions - sem emojis
        if any(word in message_lower for word in ['acho', 'penso', 'opiniÃ£o', 'acham']):
            opinion_responses = [
                "Concordo!",
                "Interessante ponto de vista!",
                "Faz sentido!"
            ]
            return random.choice(opinion_responses)
        
        # Gaming/tech topics - sem emojis
        if any(word in message_lower for word in ['game', 'jogo', 'tech', 'cÃ³digo']):
            tech_responses = [
                "Dahora! TambÃ©m curto essas paradas",
                "Massa! VocÃª manja do assunto",
                "Top! Conte mais sobre isso"
            ]
            return random.choice(tech_responses)
        
        # General positive reactions - sem emojis
        if any(word in message_lower for word in ['legal', 'massa', 'top', 'dahora']):
            positive_responses = [
                "NÃ© que Ã©!",
                "Exato!",
                "Concordo plenamente!"
            ]
            return random.choice(positive_responses)
        
        # Don't respond to everything - return None sometimes
        if random.random() < 0.4:  # 40% chance to not respond (increased to use less memory)
            return None
        
        # Generic casual responses - sem emojis
        casual_responses = [
            "Interessante isso!",
            "Hmm...",
            "Entendi!",
            "Faz sentido!"
        ]
        return random.choice(casual_responses)
    
    def _clean_message(self, message):
        """Remove mentions and clean up the message"""
        # Remove Discord mentions
        import re
        clean = re.sub(r'<@[!&]?[0-9]+>', '', message)
        clean = re.sub(r'<#[0-9]+>', '', clean)
        clean = re.sub(r'<:[a-zA-Z0-9_]+:[0-9]+>', '', clean)
        return clean.strip()
    
    def _build_gemini_prompt(self, user_name, guild_name, message):
        """Build prompt for Gemini"""
        # Detect irony/sarcasm patterns
        irony_indicators = ['nÃ©', 'claro', 'obvio', 'lÃ³gico', 'com certeza', 'aha', 'sim sim', 'tÃ¡ bom']
        has_irony = any(indicator in message.lower() for indicator in irony_indicators)
        
        # Detect heavy/awkward content
        heavy_keywords = ['caguei', 'vomitei', 'merda', 'fodeu', 'morri', 'quebrei', 'explodi', 'ferrou']
        is_heavy = any(keyword in message.lower() for keyword in heavy_keywords)
        
        # Check if it's a question
        is_question = '?' in message or any(word in message.lower() for word in ['que', 'como', 'por que', 'quando', 'onde', 'qual'])
        
        prompt = f"""
        VocÃª Ã© um bot brasileiro amigÃ¡vel e natural chamado Drode para Discord. 
        
        PERSONALIDADE AJUSTADA:
        - Seja menos sarcÃ¡stico, mais genuÃ­no e amigÃ¡vel
        - Fale portuguÃªs brasileiro natural sem exageros
        - Seja compreensivo e divertido sem ser zoeiro demais
        - Responda de forma mais direta e Ãºtil
        
        CONTEXTO:
        - UsuÃ¡rio: {user_name}
        - Servidor: {guild_name}
        - Mensagem: "{message}"
        
        INSTRUÃ‡Ã•ES ESPECÃFICAS:
        - {'ReconheÃ§a a ironia com um ğŸ˜­ se for apropriado' if has_irony else 'Responda naturalmente'}
        - {'Use ğŸ’€ para reagir ao conteÃºdo pesado' if is_heavy else 'Use emojis com moderaÃ§Ã£o'}
        - {'Responda a pergunta de forma Ãºtil' if is_question else 'Comente de forma construtiva'}
        - Use NO MÃXIMO 1-2 frases
        - Seja natural, nÃ£o force humor
        - Use poucos emojis, apenas quando necessÃ¡rio
        """
        
        return prompt
    
    def _get_contextual_fallback(self, message_content):
        """Get contextual fallback based on message content"""
        message_lower = message_content.lower()
        
        # Check for greetings
        if any(word in message_lower for word in self.greeting_words):
            return random.choice(self.greeting_responses)
        
        # Check for questions
        if any(word in message_lower for word in self.question_words) or '?' in message_content:
            return random.choice(self.question_responses)
        
        # Check for goodbyes
        if any(word in message_lower for word in self.goodbye_words):
            return random.choice(self.goodbye_responses)
        
        # Check for compliments
        if any(word in message_lower for word in self.compliment_words):
            return random.choice(self.compliment_responses)
        
        # Check for tech/gaming
        if any(word in message_lower for word in self.tech_words):
            return random.choice(self.tech_responses)
        
        # Check for emojis
        if any(emoji in message_content for emoji in ['ğŸ˜‚', 'ğŸ¤£', 'ğŸ˜„', 'ğŸ˜…']):
            return "Kkkkk tambÃ©m achei engraÃ§ado! ğŸ˜‚"
        
        # Long messages
        if len(message_content) > 100:
            return "Eita, textÃ£o! Resumindo: concordo contigo! ğŸ“"
        
        # Default fallback
        return random.choice(self.fallback_responses)
    
    def _update_conversation_history(self, user_name, user_message, bot_response):
        """Update conversation history for context - OPTIMIZED for memory"""
        # Limit total users tracked to avoid memory bloat
        max_users = 10
        if len(self.conversation_history) >= max_users:
            # Remove oldest user history
            oldest_user = next(iter(self.conversation_history))
            del self.conversation_history[oldest_user]
        
        if user_name not in self.conversation_history:
            self.conversation_history[user_name] = []
        
        # Add only essential context - reduced from 4 to 2 messages max
        self.conversation_history[user_name].extend([
            {"role": "user", "content": user_message[:100]},  # Truncate long messages
            {"role": "assistant", "content": bot_response[:100]}
        ])
        
        # Keep only last 2 messages (1 exchange) to save memory
        if len(self.conversation_history[user_name]) > 2:
            self.conversation_history[user_name] = self.conversation_history[user_name][-2:]
    
    def get_random_reaction(self):
        """Get a random reaction for variety"""
        reactions = ["ğŸ˜‚", "ğŸ¤£", "ğŸ˜„", "ğŸ˜…", "ğŸ™ƒ", "ğŸ¤ª", "ğŸ˜", "ğŸ¤–"]
        return random.choice(reactions)